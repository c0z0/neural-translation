{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translator.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "I6XLQ9or93kH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "from unicodedata import normalize\n",
        "from numpy.random import shuffle\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "class TranslateData:\n",
        "  def __init__(self, file, max_pairs=None, skip_set=0):\n",
        "    print(\"Reading file...\")\n",
        "    self.pairs = self.read_pairs(file)\n",
        "    \n",
        "    if (max_pairs != None):\n",
        "      self.pairs = self.pairs[skip_set * max_pairs :max_pairs * (skip_set + 1)]\n",
        "    \n",
        "    print(\"Cleaning data...\")\n",
        "    self.pairs = self.clean_pairs(self.pairs)\n",
        "    print(len(self.pairs))\n",
        "    \n",
        "    shuffle(self.pairs)\n",
        "    \n",
        "    self.eng_tok = Tokenizer()\n",
        "    self.ger_tok = Tokenizer()\n",
        "    \n",
        "    print(\"Fitting tokenizers...\")\n",
        "    self.eng_tok.fit_on_texts(self.pairs[:,0])\n",
        "    self.ger_tok.fit_on_texts(self.pairs[:,1])\n",
        "    \n",
        "    print(\"Tokenizing english...\")\n",
        "    self.eng_seq = self.eng_tok.texts_to_sequences(self.pairs[:,0])\n",
        "    \n",
        "    print(\"Tokenizing german...\")\n",
        "    self.ger_seq = self.ger_tok.texts_to_sequences(self.pairs[:,1])\n",
        "    \n",
        "    self.eng_maxlen = max([len(s) for s in self.eng_seq])\n",
        "    self.ger_maxlen = max([len(s) for s in self.ger_seq])\n",
        "    \n",
        "    print(\"Padding sequences...\")\n",
        "    self.eng_seq = pad_sequences(self.eng_seq, maxlen=self.eng_maxlen, padding='post')\n",
        "    self.ger_seq = pad_sequences(self.ger_seq, maxlen=self.ger_maxlen, padding='post')\n",
        "  \n",
        "    self.eng_vocab_size = len(self.eng_tok.word_index) + 1\n",
        "    self.ger_vocab_size = len(self.ger_tok.word_index) + 1\n",
        "\n",
        "\n",
        "    ylist = []\n",
        "\n",
        "    print(\"Ger to one hot...\")\n",
        "    for s in self.ger_seq:\n",
        "      enc = to_categorical(s, num_classes=self.ger_vocab_size)\n",
        "      ylist.append(enc)\n",
        "      \n",
        "    \n",
        "    self.x = self.eng_seq\n",
        "    \n",
        "    self.y = np.array(ylist)\n",
        "    del ylist\n",
        "    self.y = self.y.reshape(self.y.shape[0], self.y.shape[1], self.ger_vocab_size)\n",
        "   \n",
        "  def text_to_input(self, text):\n",
        "    input = pad_sequences(self.eng_tok.texts_to_sequences([text]), maxlen=self.eng_maxlen, padding='post')\n",
        "    \n",
        "    return input\n",
        "  \n",
        "  def pred_to_text(self, pred):\n",
        "    seq = [np.argmax(w) for w in pred]\n",
        "    \n",
        "    text = ''\n",
        "    \n",
        "    for s in seq:\n",
        "      for word, i in self.ger_tok.word_index.items():\n",
        "        if i == s:\n",
        "          text += word + ' '\n",
        "    \n",
        "    return text.strip()\n",
        "   \n",
        "  def read_pairs(self, file):\n",
        "    with open(file, 'rt', encoding='utf-8') as f:\n",
        "      text = f.read()\n",
        "    lines = text.strip().split('\\n')\n",
        "    pairs = [line.split('\\t') for line in lines]\n",
        "    \n",
        "    return pairs\n",
        "  \n",
        "  def clean_pairs(self, lines):\n",
        "    cleaned = list()\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    for pair in lines:\n",
        "      clean_pair = list()\n",
        "      for line in pair:\n",
        "        line = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "        line = line.decode('UTF-8')\n",
        "        line = line.split()\n",
        "        line = [word.lower() for word in line]\n",
        "        line = [word.translate(table) for word in line]\n",
        "        line = [re_print.sub('', w) for w in line]\n",
        "        line = [word for word in line if word.isalpha()]\n",
        "        clean_pair.append(' '.join(line))\n",
        "      cleaned.append(clean_pair)\n",
        "    return np.array(cleaned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ti-n66G5t2gg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = TranslateData('./deu.txt', max_pairs=12500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ecoDF5gOA1Km",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, TimeDistributed, RepeatVector, Dropout, Bidirectional\n",
        "\n",
        "\n",
        "def get_model(eng_vocab_size, ger_vocab_size, eng_maxlen, ger_maxlen, n_cells):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(eng_vocab_size, n_cells, input_shape=(eng_maxlen, ), mask_zero=True))\n",
        "  model.add(Bidirectional(LSTM(n_cells)))\n",
        "  model.add(RepeatVector(ger_maxlen))\n",
        "  model.add(Bidirectional(LSTM(n_cells, return_sequences=True)))\n",
        "  model.add(Dropout(.1))\n",
        "  model.add(TimeDistributed(Dense(ger_vocab_size, activation='softmax')))\n",
        "  \n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vmm_RGfPIlqR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = get_model(data.eng_vocab_size, data.ger_vocab_size,  data.eng_maxlen, data.ger_maxlen, 512)\n",
        "plot_model(model, to_file='model-bi.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mtSTE4s1KX2c",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "callback_list = [ModelCheckpoint('./translate-model-ger-bi.h5', monitor='loss'), EarlyStopping(monitor='loss', min_delta=0.01, patience=0)]\n",
        "\n",
        "model.fit(data.x, data.y, epochs=100, verbose=True, validation_split=.1, callbacks=callback_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9S5VfFWiK-vc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from random import choice\n",
        "\n",
        "for i in range(20):\n",
        "  pair = choice(data.pairs)\n",
        "  p = data.pred_to_text(model.predict(data.text_to_input(pair[0]))[0])\n",
        "  print(\"%s => %s (%s)\" % (pair[0], p, pair[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}